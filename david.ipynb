{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529964ab",
   "metadata": {},
   "source": [
    "# Comparativo: Mini-Batches vs Batch Completo com e sem Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa08343",
   "metadata": {},
   "source": [
    "### üìä Gr√°ficos Comparativos\n",
    "\n",
    "![Batch vs Full - Sem Clipping](imgs/batch_vs_full_sem_clipping.png)\n",
    "![Batch vs Full - Com Clipping](imgs/batch_vs_full_com_clipping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c2fa4",
   "metadata": {},
   "source": [
    "### üîπ Matrizes de Confus√£o\n",
    "\n",
    "**Batch Completo - Sem Clipping**\n",
    "\n",
    "![Confusion Matrix - Sem Clipping](imgs/confusion_matrix_batch_completo_sem_clipping.png)\n",
    "\n",
    "**Batch Completo - Com Clipping**\n",
    "\n",
    "![Confusion Matrix - Com Clipping](imgs/confusion_matrix_batch_completo_com_clipping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172823a",
   "metadata": {},
   "source": [
    "### üß† Por que utilizamos Gradient Clipping quando eu quis testar o batch total?\n",
    "\n",
    "Durante os testes com treinamento usando batch completo (60.000 amostras), observamos que o modelo apresentava explos√£o de gradientes, evidenciada por valores extremamente altos de *loss* (acima de 30) e uma acur√°cia de 10% (equivalente a chute aleat√≥rio).\n",
    "\n",
    "Esse problema ocorre porque o uso de batches grandes reduz a frequ√™ncia de atualiza√ß√£o dos pesos, concentrando muito gradiente em uma √∫nica atualiza√ß√£o, o que pode provocar valores extremos nas ativa√ß√µes e pesos. Isso afeta fun√ß√µes como softmax e causa instabilidade num√©rica.\n",
    "\n",
    "Para resolver isso, implementamos o **gradient clipping**, que limita a norma L2 dos gradientes a um valor m√°ximo (neste caso, 5.0). Se a norma dos gradientes for maior que esse limite, todos os gradientes s√£o escalados proporcionalmente. Isso estabiliza o treinamento, evita explos√µes e melhora a converg√™ncia.\n",
    "\n",
    "Com a t√©cnica aplicada, conseguimos treinar a rede mesmo com batch completo, mantendo a *loss* dentro de valores razo√°veis e observando uma melhoria na acur√°cia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80bce22",
   "metadata": {},
   "source": [
    "### üî¢ Como o Gradient Clipping funciona matematicamente?\n",
    "\n",
    "Seja $\\mathbf{g} \\in \\mathbb{R}^n$ o vetor concatenado de todos os gradientes do modelo (por exemplo, pesos e bias). O clipping por norma L2 funciona da seguinte forma:\n",
    "\n",
    "1. Calcula-se a norma:\n",
    "\n",
    "   $$\n",
    "   \\|\\mathbf{g}\\|_2 = \\sqrt{g_1^2 + g_2^2 + \\ldots + g_n^2}\n",
    "   $$\n",
    "\n",
    "2. Se $\\|\\mathbf{g}\\|_2 \\leq \\tau$, nada √© feito ($\\tau$ √© o limite definido, como 5.0).\n",
    "\n",
    "3. Caso contr√°rio, aplica-se um fator de escala:\n",
    "\n",
    "   $$\n",
    "   \\mathbf{g}_{\\text{clipped}} = \\mathbf{g} \\cdot \\frac{\\tau}{\\|\\mathbf{g}\\|_2 + \\varepsilon}\n",
    "   $$\n",
    "\n",
    "Esse reescalonamento garante que o vetor de gradiente final tenha no m√°ximo a norma desejada, sem alterar sua dire√ß√£o.\n",
    "\n",
    "Isso evita que gradientes extremamente grandes causem saltos muito bruscos na atualiza√ß√£o dos pesos, estabilizando o aprendizado, especialmente em redes profundas ou com batches grandes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a627cc",
   "metadata": {},
   "source": [
    "### ‚ùå Sem usar o Clipping:\n",
    "```\n",
    "    Epoch 1/30, Loss: 2.4086, Acc: 0.1053, Val Loss: 27.9799, Val Acc: 0.1899\n",
    "    Epoch 2/30, Loss: 27.9862, Acc: 0.1897, Val Loss: 31.0849, Val Acc: 0.1000\n",
    "    Epoch 3/30, Loss: 31.0849, Acc: 0.1000, Val Loss: 28.6563, Val Acc: 0.1701\n",
    "    Epoch 4/30, Loss: 28.5377, Acc: 0.1735, Val Loss: 28.3900, Val Acc: 0.1004\n",
    "    Epoch 5/30, Loss: 28.3917, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 6/30, Loss: 31.0734, Acc: 0.1003, Val Loss: 24.2246, Val Acc: 0.1004\n",
    "    Epoch 7/30, Loss: 24.2253, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 8/30, Loss: 31.0740, Acc: 0.1003, Val Loss: 31.0849, Val Acc: 0.1000\n",
    "    Epoch 9/30, Loss: 31.0826, Acc: 0.1001, Val Loss: 27.8344, Val Acc: 0.1004\n",
    "    Epoch 10/30, Loss: 27.8383, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 11/30, Loss: 31.0751, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 12/30, Loss: 31.0740, Acc: 0.1003, Val Loss: 30.2935, Val Acc: 0.1004\n",
    "    Epoch 13/30, Loss: 30.2958, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 14/30, Loss: 31.0728, Acc: 0.1003, Val Loss: 25.2368, Val Acc: 0.1004\n",
    "    Epoch 15/30, Loss: 25.2385, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 16/30, Loss: 31.0728, Acc: 0.1003, Val Loss: 26.7380, Val Acc: 0.1000\n",
    "    Epoch 17/30, Loss: 26.7355, Acc: 0.1001, Val Loss: 27.0227, Val Acc: 0.1004\n",
    "    Epoch 18/30, Loss: 27.0250, Acc: 0.1003, Val Loss: 28.9454, Val Acc: 0.1004\n",
    "    Epoch 19/30, Loss: 28.9477, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 20/30, Loss: 31.0734, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 21/30, Loss: 31.0745, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 22/30, Loss: 31.0734, Acc: 0.1003, Val Loss: 27.4549, Val Acc: 0.1004\n",
    "    Epoch 23/30, Loss: 27.4566, Acc: 0.1003, Val Loss: 29.5507, Val Acc: 0.1004\n",
    "    Epoch 24/30, Loss: 29.5524, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 25/30, Loss: 31.0728, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 26/30, Loss: 31.0728, Acc: 0.1003, Val Loss: 26.2962, Val Acc: 0.1000\n",
    "    Epoch 27/30, Loss: 26.2939, Acc: 0.1001, Val Loss: 26.9832, Val Acc: 0.1004\n",
    "    Epoch 28/30, Loss: 26.9852, Acc: 0.1003, Val Loss: 27.8167, Val Acc: 0.1004\n",
    "    Epoch 29/30, Loss: 27.8189, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Epoch 30/30, Loss: 31.0734, Acc: 0.1003, Val Loss: 31.0711, Val Acc: 0.1004\n",
    "    Batch Completo - Test Accuracy: 0.1004 | Test Loss: 31.0711\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a92c7e",
   "metadata": {},
   "source": [
    "### ‚úÖ Depois do Clipping:\n",
    "```\n",
    "    Epoch 1/30, Loss: 2.5320, Acc: 0.1170, Val Loss: 2.3967, Val Acc: 0.1661\n",
    "    Epoch 2/30, Loss: 2.3971, Acc: 0.1635, Val Loss: 2.2847, Val Acc: 0.2195\n",
    "    Epoch 3/30, Loss: 2.2860, Acc: 0.2144, Val Loss: 2.1911, Val Acc: 0.2662\n",
    "    Epoch 4/30, Loss: 2.1933, Acc: 0.2648, Val Loss: 2.1113, Val Acc: 0.3188\n",
    "    Epoch 5/30, Loss: 2.1142, Acc: 0.3202, Val Loss: 2.0400, Val Acc: 0.3723\n",
    "    Epoch 6/30, Loss: 2.0432, Acc: 0.3690, Val Loss: 1.9731, Val Acc: 0.4137\n",
    "    Epoch 7/30, Loss: 1.9765, Acc: 0.4097, Val Loss: 1.9090, Val Acc: 0.4507\n",
    "    Epoch 8/30, Loss: 1.9124, Acc: 0.4494, Val Loss: 1.8474, Val Acc: 0.4855\n",
    "    Epoch 9/30, Loss: 1.8508, Acc: 0.4842, Val Loss: 1.7882, Val Acc: 0.5178\n",
    "    Epoch 10/30, Loss: 1.7916, Acc: 0.5136, Val Loss: 1.7316, Val Acc: 0.5396\n",
    "    Epoch 11/30, Loss: 1.7349, Acc: 0.5374, Val Loss: 1.6774, Val Acc: 0.5585\n",
    "    Epoch 12/30, Loss: 1.6807, Acc: 0.5587, Val Loss: 1.6256, Val Acc: 0.5766\n",
    "    Epoch 13/30, Loss: 1.6289, Acc: 0.5769, Val Loss: 1.5762, Val Acc: 0.5899\n",
    "    Epoch 14/30, Loss: 1.5792, Acc: 0.5916, Val Loss: 1.5289, Val Acc: 0.6014\n",
    "    Epoch 15/30, Loss: 1.5317, Acc: 0.6036, Val Loss: 1.4836, Val Acc: 0.6120\n",
    "    Epoch 16/30, Loss: 1.4863, Acc: 0.6133, Val Loss: 1.4403, Val Acc: 0.6191\n",
    "    Epoch 17/30, Loss: 1.4428, Acc: 0.6213, Val Loss: 1.3990, Val Acc: 0.6263\n",
    "    Epoch 18/30, Loss: 1.4012, Acc: 0.6287, Val Loss: 1.3594, Val Acc: 0.6340\n",
    "    Epoch 19/30, Loss: 1.3615, Acc: 0.6344, Val Loss: 1.3217, Val Acc: 0.6394\n",
    "    Epoch 20/30, Loss: 1.3236, Acc: 0.6397, Val Loss: 1.2856, Val Acc: 0.6450\n",
    "    Epoch 21/30, Loss: 1.2873, Acc: 0.6445, Val Loss: 1.2512, Val Acc: 0.6495\n",
    "    Epoch 22/30, Loss: 1.2527, Acc: 0.6487, Val Loss: 1.2185, Val Acc: 0.6534\n",
    "    Epoch 23/30, Loss: 1.2197, Acc: 0.6530, Val Loss: 1.1873, Val Acc: 0.6584\n",
    "    Epoch 24/30, Loss: 1.1883, Acc: 0.6573, Val Loss: 1.1575, Val Acc: 0.6625\n",
    "    Epoch 25/30, Loss: 1.1583, Acc: 0.6619, Val Loss: 1.1293, Val Acc: 0.6676\n",
    "    Epoch 26/30, Loss: 1.1298, Acc: 0.6655, Val Loss: 1.1024, Val Acc: 0.6706\n",
    "    Epoch 27/30, Loss: 1.1027, Acc: 0.6695, Val Loss: 1.0768, Val Acc: 0.6753\n",
    "    Epoch 28/30, Loss: 1.0769, Acc: 0.6742, Val Loss: 1.0525, Val Acc: 0.6792\n",
    "    Epoch 29/30, Loss: 1.0524, Acc: 0.6790, Val Loss: 1.0294, Val Acc: 0.6831\n",
    "    Epoch 30/30, Loss: 1.0291, Acc: 0.6828, Val Loss: 1.0075, Val Acc: 0.6882\n",
    "    Batch Completo - Test Accuracy: 0.6882 | Test Loss: 1.0075\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8468ed1",
   "metadata": {},
   "source": [
    "Essa compara√ß√£o evidencia o impacto direto do gradient clipping na estabilidade e performance de treinamento quando se usa batch completo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d444b39",
   "metadata": {},
   "source": [
    "\n",
    "## üîß Tipos de Normaliza√ß√£o Utilizados\n",
    "![Gr√°fico Normaliza√ß√µes](imgs/compare_normalization_20250425_090021.png)\n",
    "\n",
    "Durante os experimentos com o dataset Fashion MNIST, foram testadas tr√™s abordagens de normaliza√ß√£o dos dados de entrada:\n",
    "\n",
    "1. **Sem normaliza√ß√£o**  \n",
    "   Os valores dos pixels permaneceram no intervalo original \\([0, 255]\\).\n",
    "\n",
    "2. **Normaliza√ß√£o Min-Max** (utilizada como padr√£o na maioria dos testes)  \n",
    "   Os valores foram escalados para o intervalo \\([0, 1]\\) dividindo-se por 255:\n",
    "   ```python\n",
    "   X = X / 255.0\n",
    "   ```\n",
    "\n",
    "3. **Padroniza√ß√£o Z-score**  \n",
    "   Os valores foram centralizados em 0 e escalados para desvio padr√£o 1:\n",
    "   ```python\n",
    "   X = (X - X.mean()) / X.std()\n",
    "   ```\n",
    "\n",
    "### üìå Observa√ß√µes\n",
    "\n",
    "- A normaliza√ß√£o \\([0, 1]\\) foi usada como padr√£o nos testes principais: *batch completo, clipping e shuffling*.\n",
    "- A padroniza√ß√£o Z-score foi utilizada apenas nos experimentos espec√≠ficos de compara√ß√£o de normaliza√ß√µes.\n",
    "\n",
    "\n",
    "![Matriz de confus√£o Z-Score](imgs/confusion_matrix_z-score_20250425_090027.png)\n",
    "![Matriz de confus√£o Norm [0,1]](imgs/confusion_matrix_normaliza√ß√£o_min-max_[0,1]_20250425_090026.png)\n",
    "![Matriz de confus√£o sem Norm](imgs/confusion_matrix_sem_normaliza√ß√£o_20250425_090025.png)\n",
    "\n",
    "\n",
    "Embora a padroniza√ß√£o Z-score seja comum em dados tabulares, para imagens como o Fashion MNIST, a normaliza√ß√£o Min-Max [0, 1] apresentou melhor desempenho. Isso se deve √† compatibilidade com a distribui√ß√£o original dos pixels e √† ativa√ß√£o ReLU usada na rede, que responde melhor a entradas positivas. J√° o Z-score introduz valores negativos e distorce as rela√ß√µes locais entre os pixels, dificultando o aprendizado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd7e0e",
   "metadata": {},
   "source": [
    "## üîÑ Comparativo com e sem Shuffling\n",
    "\n",
    "![Gr√°fico Shuffle vs No Shuffle](imgs/compare_shuffle_20250425_222030.png)\n",
    "\n",
    "Apesar da expectativa de que o **embaralhamento dos dados (shuffling)** melhore significativamente o desempenho da rede, o resultado real mostra que:\n",
    "\n",
    "- As curvas de *loss* foram quase id√™nticas nos dois casos.\n",
    "- A acur√°cia de valida√ß√£o sem shuffle chegou a ser levemente melhor em alguns momentos.\n",
    "\n",
    "### üß† Como explicar isso?\n",
    "\n",
    "1. **O Fashion MNIST j√° vem embaralhado.**\n",
    "   - A ordem dos dados n√£o segue um padr√£o previs√≠vel como \"classe 0 primeiro, depois 1...\".\n",
    "   - Isso reduz o impacto do shuffling adicional.\n",
    "\n",
    "2. **Mini-batches pequenos j√° trazem variedade.**\n",
    "   - Como o batch size √© 32, cada mini-batch √© suficientemente diverso.\n",
    "   - O modelo j√° recebe \"fatias aleat√≥rias\" do conjunto.\n",
    "\n",
    "3. **Diferen√ßas pequenas podem ser ru√≠do estat√≠stico.**\n",
    "   - O ideal seria rodar o experimento v√°rias vezes e tirar m√©dias para confirmar.\n",
    "\n",
    "> Mesmo sendo considerada uma boa pr√°tica, a t√©cnica de shuffling teve impacto limitado neste experimento. Isso se deve ao fato de o Fashion MNIST j√° estar embaralhado e ao uso de mini-batches pequenos, que j√° introduzem diversidade suficiente. Portanto, a diferen√ßa entre usar ou n√£o shuffling foi marginal neste caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42857a95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478d188",
   "metadata": {},
   "source": [
    "## üß™ Experimento: Impacto do Tamanho do Batch no Treinamento\n",
    "\n",
    "Este experimento avalia como diferentes valores de `batch_size` afetam o desempenho da rede neural, utilizando os seguintes cen√°rios:\n",
    "\n",
    "- **Batch Size = 1** ‚Üí Stochastic Gradient Descent (SGD)\n",
    "- **Batch Size = 32** ‚Üí Mini-Batch padr√£o\n",
    "- **Batch Size = 512** ‚Üí Grande lote\n",
    "\n",
    "### üéØ Gr√°ficos de Desempenho\n",
    "\n",
    "![Gr√°fico Loss e Acur√°cia por Batch](imgs/compare_batch_size_20250425_224939.png)\n",
    "\n",
    "### üîé Matrizes de Confus√£o\n",
    "\n",
    "**Batch Stochastic (1)**  \n",
    "![Matriz Confus√£o SGD](imgs/confusion_matrix_batch_stochastic_(1)_20250425_225017.png)\n",
    "\n",
    "**Batch Mini-Batch (32)**  \n",
    "![Matriz Confus√£o Mini-Batch](imgs/confusion_matrix_batch_mini-batch_(32)_20250425_225022.png)\n",
    "\n",
    "**Batch Grande (512)**  \n",
    "![Matriz Confus√£o Large Batch](imgs/confusion_matrix_batch_large_batch_(512)_20250425_225028.png)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä An√°lise dos Resultados\n",
    "\n",
    "| Tamanho do Batch | Acur√°cia Val | Observa√ß√µes |\n",
    "|------------------|--------------|-------------|\n",
    "| **1 (SGD)**      | Alta, mas inst√°vel | Curvas de loss com muito ru√≠do, tempo de treino alto |\n",
    "| **32**           | Melhor resultado geral | Est√°vel, boa acur√°cia, √≥tima generaliza√ß√£o |\n",
    "| **512**          | Converg√™ncia mais suave | Est√°vel, por√©m menor acur√°cia e tend√™ncia a m√≠nimos locais |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Explica√ß√£o T√©cnica\n",
    "\n",
    "- **SGD (`batch_size=1`)**: atualiza os pesos a cada exemplo ‚Üí muito ru√≠do ‚Üí pode escapar de m√≠nimos ruins, mas demora e oscila.\n",
    "- **Mini-batch (`batch_size=32`)**: balanceia ru√≠do e estabilidade, garantindo boa generaliza√ß√£o.\n",
    "- **Batch grande (`batch_size=512`)**: atualiza√ß√µes muito est√°veis, por√©m menos sens√≠veis a detalhes ‚Üí pior generaliza√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùó Observa√ß√£o sobre a Classe 6 (Shirt)\n",
    "\n",
    "A classe `6` foi **consistentemente a mais mal predita** em todos os cen√°rios, com destaque para o batch grande. Isso ocorre porque:\n",
    "\n",
    "- √â visualmente parecida com outras classes como camiseta (0) e pul√¥ver (2)\n",
    "- Tem menos caracter√≠sticas visuais distintas\n",
    "- Batches grandes tendem a **aprender padr√µes m√©dios**, e isso **prejudica a sensibilidade √†s nuances entre essas classes**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Conclus√£o\n",
    "\n",
    "> O tamanho do batch influencia diretamente a estabilidade e a capacidade de generaliza√ß√£o do modelo. Embora batchs grandes sejam eficientes, podem levar √† perda de detalhes importantes ‚Äî especialmente para classes amb√≠guas. O uso de `batch_size = 32` demonstrou o melhor equil√≠brio entre performance e robustez.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
